{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "75226455",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.python/current/lib/python3.12/site-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "import numpy as np\n",
    "\n",
    "class F1Score(tf.keras.metrics.Metric):\n",
    "    def __init__(self, name='f1_score', **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.precision = Precision()\n",
    "        self.recall = Recall()\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        self.precision.update_state(y_true, y_pred, sample_weight)\n",
    "        self.recall.update_state(y_true, y_pred, sample_weight)\n",
    "\n",
    "    def result(self):\n",
    "        p = self.precision.result()\n",
    "        r = self.recall.result()\n",
    "        return 2 * ((p * r) / (p + r + 1e-6))  # Evita división por cero\n",
    "\n",
    "    def reset_states(self):\n",
    "        self.precision.reset_states()\n",
    "        self.recall.reset_states()\n",
    "\n",
    "\n",
    "def create_progress_evaluator_model():\n",
    "    \"\"\"\n",
    "    Crea un modelo para evaluar el progreso del usuario y predecir\n",
    "    la probabilidad de recordar una palabra.\n",
    "    \"\"\"\n",
    "    # Definir el modelo\n",
    "    model = Sequential([\n",
    "    # Capa de entrada - 3 características\n",
    "    Dense(16, activation='relu', input_shape=(3,)),\n",
    "    Dropout(0.2), # Prevenir overfitting\n",
    "    # Capa oculta\n",
    "    Dense(8, activation='relu'),\n",
    "    Dropout(0.1),\n",
    "    # Capa de salida - probabilidad de recordar la palabra\n",
    "    Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    # Compilar el modelo\n",
    "    model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=[\"F1Score\",'accuracy']\n",
    "    )\n",
    "    return model\n",
    "# Crear el modelo\n",
    "progress_model = create_progress_evaluator_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0bf25314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m95555/95555\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 1ms/step - F1Score: 0.9183 - accuracy: 0.8437 - loss: 0.5714 - val_F1Score: 0.9174 - val_accuracy: 0.8477 - val_loss: 0.3520\n",
      "Epoch 2/15\n",
      "\u001b[1m95555/95555\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 1ms/step - F1Score: 0.9187 - accuracy: 0.8499 - loss: 0.3429 - val_F1Score: 0.9174 - val_accuracy: 0.8475 - val_loss: 0.3394\n",
      "Epoch 3/15\n",
      "\u001b[1m95555/95555\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 1ms/step - F1Score: 0.9187 - accuracy: 0.8496 - loss: 0.3307 - val_F1Score: 0.9174 - val_accuracy: 0.8475 - val_loss: 0.3236\n",
      "Epoch 4/15\n",
      "\u001b[1m95555/95555\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 1ms/step - F1Score: 0.9186 - accuracy: 0.8495 - loss: 0.3241 - val_F1Score: 0.9174 - val_accuracy: 0.8475 - val_loss: 0.3067\n",
      "Epoch 5/15\n",
      "\u001b[1m95555/95555\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 1ms/step - F1Score: 0.9188 - accuracy: 0.8498 - loss: 0.3209 - val_F1Score: 0.9174 - val_accuracy: 0.8475 - val_loss: 0.3275\n",
      "Epoch 6/15\n",
      "\u001b[1m95555/95555\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 1ms/step - F1Score: 0.9186 - accuracy: 0.8495 - loss: 0.3197 - val_F1Score: 0.9174 - val_accuracy: 0.8475 - val_loss: 0.3058\n",
      "Epoch 7/15\n",
      "\u001b[1m95555/95555\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 1ms/step - F1Score: 0.9186 - accuracy: 0.8495 - loss: 0.3162 - val_F1Score: 0.9174 - val_accuracy: 0.8475 - val_loss: 0.3062\n",
      "Epoch 8/15\n",
      "\u001b[1m95555/95555\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 1ms/step - F1Score: 0.9186 - accuracy: 0.8495 - loss: 0.3164 - val_F1Score: 0.9174 - val_accuracy: 0.8475 - val_loss: 0.3047\n",
      "Epoch 9/15\n",
      "\u001b[1m95555/95555\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 1ms/step - F1Score: 0.9187 - accuracy: 0.8497 - loss: 0.3137 - val_F1Score: 0.9174 - val_accuracy: 0.8475 - val_loss: 0.3148\n",
      "Epoch 10/15\n",
      "\u001b[1m95555/95555\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 1ms/step - F1Score: 0.9187 - accuracy: 0.8496 - loss: 0.3137 - val_F1Score: 0.9174 - val_accuracy: 0.8475 - val_loss: 0.3081\n",
      "Epoch 11/15\n",
      "\u001b[1m95555/95555\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 1ms/step - F1Score: 0.9187 - accuracy: 0.8497 - loss: 0.3117 - val_F1Score: 0.9174 - val_accuracy: 0.8475 - val_loss: 0.3105\n",
      "Epoch 12/15\n",
      "\u001b[1m95555/95555\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 1ms/step - F1Score: 0.9185 - accuracy: 0.8494 - loss: 0.3110 - val_F1Score: 0.9174 - val_accuracy: 0.8475 - val_loss: 0.3191\n",
      "Epoch 13/15\n",
      "\u001b[1m95555/95555\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 1ms/step - F1Score: 0.9188 - accuracy: 0.8497 - loss: 0.3105 - val_F1Score: 0.9174 - val_accuracy: 0.8475 - val_loss: 0.2994\n",
      "Epoch 14/15\n",
      "\u001b[1m95555/95555\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 1ms/step - F1Score: 0.9188 - accuracy: 0.8500 - loss: 0.3092 - val_F1Score: 0.9174 - val_accuracy: 0.8475 - val_loss: 0.3177\n",
      "Epoch 15/15\n",
      "\u001b[1m95555/95555\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 1ms/step - F1Score: 0.9188 - accuracy: 0.8509 - loss: 0.3087 - val_F1Score: 0.9174 - val_accuracy: 0.8475 - val_loss: 0.3017\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "def generate_synthetic_training_data(num_samples=1000):\n",
    "    \"\"\"\n",
    "    Genera datos sintéticos para el entrenamiento inicial del modelo.\n",
    "    \"\"\"\n",
    "    X = np.zeros((num_samples, 7))\n",
    "    y = np.zeros((num_samples, 1))\n",
    "    for i in range(num_samples):\n",
    "    # Generar características aleatorias\n",
    "    times_reviewed = np.random.randint(1, 10)\n",
    "    times_correct = np.random.randint(0, times_reviewed + 1)\n",
    "    times_incorrect = times_reviewed - times_correct\n",
    "    days_since_last = np.random.randint(0, 30)\n",
    "    avg_response_time = np.random.uniform(1.0, 10.0)\n",
    "    word_difficulty = np.random.randint(1, 6)\n",
    "    word_level_idx = np.random.randint(0, 4) # 0:A1, 1:A2, 2:B1, 3:B2\n",
    "    # Probabilidad \"real\" (sintética) basada en reglas lógicas\n",
    "    p_remember = 0.9 * (times_correct / max(1, times_reviewed)) - \\\n",
    "    0.05 * days_since_last - \\\n",
    "    0.1 * word_difficulty + \\\n",
    "    0.2 * (1.0 - min(1.0, avg_response_time / 10.0))\n",
    "    # Ajustar a rango [0, 1]\n",
    "    p_remember = max(0.01, min(0.99, p_remember))\n",
    "    # Asignar valores\n",
    "    X[i] = [times_reviewed, times_correct, times_incorrect,\n",
    "    days_since_last, times_correct/max(1, times_reviewed),\n",
    "    avg_response_time, word_difficulty]\n",
    "    # El objetivo es 1 si se recuerda, 0 si no\n",
    "    y[i] = 1 if np.random.random() < p_remember else 0\n",
    "    return X, y\n",
    "'''\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('duolingo.csv')\n",
    "\n",
    "# Generar datos sintéticos\n",
    "X_train, y_train = df.loc[:,(\"times_reviewed\",\"times_correct\",\"delta\")],df.loc[:,\"recall\"] \n",
    "# Entrenamiento inicial\n",
    "progress_model.fit(X_train, y_train, epochs=15, batch_size=32, validation_split=0.2)\n",
    "# Guardar el modelo\n",
    "progress_model.save('vocabulary_progress_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "979a45d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estructura de datos de entrada\n",
    "\n",
    "user_word_interaction = {\n",
    " \"user_id\": \"user123\",\n",
    " \"word_id\": \"word456\",\n",
    " \"features\": {\n",
    " \"times_reviewed\": 2, # Número de veces que ha visto la palabra\n",
    " \"times_correct\": 1, # Veces que respondió correctamente\n",
    " \"delta\": 24, # Días desde la última revisión\n",
    " }\n",
    "}\n",
    "#dias 24 48 72 96 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "76f3a3d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5212194323539734"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def determine_review_priority(user_words_data):\n",
    "    \"\"\"\n",
    "    Determina qué palabras necesitan ser repasadas con mayor prioridad.\n",
    "    Args:\n",
    "    user_words_data: Lista de diccionarios con datos de interacción\n",
    "    Returns:\n",
    "    Lista de IDs de palabras ordenadas por prioridad de repaso\n",
    "    \"\"\"\n",
    "    word_priorities = []\n",
    "    for word_data in user_words_data:\n",
    "    recall_prob = predict_recall_probability(word_data)\n",
    "    # Calcular prioridad: palabras con baja probabilidad de ser recordadas\n",
    "    # pero que han sido revisadas tienen alta prioridad\n",
    "    priority_score = (1 - recall_prob) * (word_data[\"times_reviewed\"] + 1)\n",
    "    word_priorities.append({\n",
    "    \"word_id\": word_data[\"word_id\"],\n",
    "    \"recall_probability\": recall_prob,\n",
    "    \"priority_score\": priority_score\n",
    "    })\n",
    "    # Ordenar por prioridad (mayor primero)\n",
    "    sorted_priorities = sorted(word_priorities,\n",
    "    key=lambda x: x[\"priority_score\"],\n",
    "    reverse=True)\n",
    "    return [item[\"word_id\"] for item in sorted_priorities]\n",
    "\n",
    "'''\n",
    "\n",
    "def predict_recall_probability(user_word_data):\n",
    "    \"\"\"\n",
    "    Predice la probabilidad de que un usuario recuerde una palabra\n",
    "    basado en sus interacciones previas.\n",
    "    Args:\n",
    "    user_word_data: Dict con los datos de interacción usuario-palabra\n",
    "    Returns:\n",
    "    Probabilidad (0-1) de que el usuario recuerde la palabra\n",
    "    \"\"\"\n",
    "    # Extraer características\n",
    "    features = [\n",
    "    user_word_data[\"times_reviewed\"],\n",
    "    user_word_data[\"times_correct\"],\n",
    "    user_word_data[\"delta\"],\n",
    "    ]\n",
    "    # Convertir a array y dar forma adecuada\n",
    "    features_array = np.array(features).reshape(1, -1)\n",
    "    # Realizar predicción\n",
    "    probability = progress_model.predict(features_array)[0][0]\n",
    "    return float(probability)\n",
    "\n",
    "\n",
    "predict_recall_probability(user_word_interaction[\"features\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4c4950c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7212440371513367"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Estructura de datos de entrada\n",
    "\n",
    "user_word_interaction = {\n",
    " \"user_id\": \"user123\",\n",
    " \"word_id\": \"word456\",\n",
    " \"features\": {\n",
    " \"times_reviewed\": 7, # Número de veces que ha visto la palabra\n",
    " \"times_correct\": 6, # Veces que respondió correctamente\n",
    " \"delta\": 24, # Días desde la última revisión\n",
    " }\n",
    "}\n",
    "#dias 24 48 72 96 120\n",
    "\n",
    "predict_recall_probability(user_word_interaction[\"features\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
